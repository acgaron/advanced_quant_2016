#hello and welcome to the regression assignment. 
#I will be guiding you through the below code STEP BY STEP. 
#If you do not have R experience, please do not zip ahead
#it will take time to see what you did 
#and how to fix it, and may impact the time we have available. 

#Please note that this is a text file -- NOT A WORD DOC. 
#You will be able to copy paste everything straight from this document into R.

# NOTE: IN R, WE SAVE OUR WORK IN A DIFFERENT WAY THAN THE TRADITIONAL METHOD. 
# TO CONTINUE WORKING ON THIS AFTER CLASS, SAVE EACH LINE THAT YOU ENTER IN A SEPARATE DOCUMENT, 
# LIKE I HAVE DONE IN THIS SCRIPT.
# I HIGHLY RECOMMEND A TEXT EDITOR, SUCH AS NOTEPAD in WINDOWS or TEXT EDITOR IN OS X.
# WORD SOMETIMES DOES NOT LET YOU COPY PASTE IN -- IT IS VERY ANNOYING.
# WE NEVER SAVE ANYTHING IN THE R ENVIRONMENT -- WE JUST COPY PASTE CODE LIKE THIS INTO R.
# I WILL GO OVER THIS FURTHER BEFORE CLASS CONCLUDES.


#now lets load in the dataset


calschool.1 <- read.csv("D:/calschool-1.csv") # this is from the school's PC. you should #use the import button in the upper right of R Studio.

View(calschool.1)

calschool <- calschool.1 #you can name this whatever you want, but I recommend calschool because it will be in line with the code below. 

#packages we are going to be using today:

install.packages("car") #only need to do this one once
install.packages("psych") #only need to do this one once

library("car") #need this one every time you close R
library("psych") #need this one every time you close R

#THIS REMOVES SCIENTIFIC NOTATION 
options(scipen=999) #need this one every time you close R

#STEP 1: no R code

#STEP 2: no R code

#STEP 3: no R code

#STEP 4: Perform basic checks of the candidate variables. 
#Do you have any missing value or out of range data problems? 
#If so, what did you do to resolve them, if anything?

summary_calschools <- describe(calschool) 
View(summary_calschools)

#this creates a nice table for us to look at summary statistics. 
#here we can see missing values, ranges, measures of central tendancy, and standard deviation.

#Step 5: What did your check of the correlation matrix find? 
#Did you add any variables to the end of you list based on it? Does it look like you need to worry about multicollinearity? 

#remember this from the lab? this is a function that gives us not only our Pearson's Coefficients, but also gives us our p-values too! 
#when looking at output generated by cor.prob, remember, p values are above and coefficients are below the NAs. 


cor.prob <- function (X, dfr = nrow(X) - 2) {
  
R <- cor(X, use="pairwise.complete.obs")
 above <- row(R) < col(R)
  r2 <- R[above]^2
  
Fstat <- r2 * dfr/(1 - r2)
  R[above] <- 1 - pf(Fstat, 1, dfr)
  R[row(R) == col(R)] <- NA
  R

}

correlation_table_calschool <- cor.prob(calschool)

View(correlation_table_calschool)

write.csv(correlation_table_calschool, file = "Correlation Matrix California Schools.csv")

#open this file in excel and look at the correlation scores. any note worthy correlations that might help you build your model? Which variables have the strongest relationships with academic performance?
#would these variables be good to include in a regression analysis?

#STEP 6 - no R code

#STEP 7: REGRESSION! Add your first independent variable. Show your bivariate model. Did it accord with your expectations? 

regression_1 <- lm(acadperf ~ YOUR_VARIABLE_1, data=calschool)

summary(regression_1) #this tells us the results of our regression. Is it in line with your expectations?

#STEP 8: Check for regression violations for this bivariate mode. Did you find any major violations? 

#to analyze residuals and test assumptions, here we can create the proper graphs / statistics. 
#Enter these in one by one, and look at each graph to check assumptions before proceeding to the next graph.

hist(scale(regression_1$residuals))
qqnorm(scale(regression_1$residuals))
plot(scale(regression_1$fitted),scale(regression_1$residuals))

#what if we want standardized coefficients? R is a little difficult in that it doesn't give them as part of the standard output. 
#All standard coefficients do is standardize the unit of analysis, so we can compare coefficients. 

lm(scale(acadperf) ~ scale(YOUR_VARIABLE_1), data=calschool)

#how about standardized residuals?
regression_1$standardized.residuals <- rstandard(regression_1)

regression_1$large_residual <- regression_1$standardized.residuals >2 | regression_1$standardized.residuals < -2

sum(regression_1$large_residual)
# this value gives us the number of residuals with an absolute value more than 2.

#durban-watson
dwt(regression_1)

#STEP 9: Sequentially build up the model adding variables in the order you specified (donÕt check reg. assumptions at each stage) 
#TO CHECK MULTICOLLINEARITY use this command vif(regression_model_you_are_analyzing)

regression_2 <- lm(acadperf ~ YOUR_VARIABLE_1 + YOUR_VARIABLE_2, data=calschool)

regression_3 <- lm(acadperf ~ YOUR_VARIABLE_1 + YOUR_VARIABLE_2 + YOUR_VARIABLE_3, data=calschool)

regression_4 <- lm(acadperf ~ YOUR_VARIABLE_1 + YOUR_VARIABLE_2 + YOUR_VARIABLE_3 + YOUR_VARIABLE_4, data=calschool)

regression_5 <- lm(acadperf ~ YOUR_VARIABLE_1 + YOUR_VARIABLE_2 + YOUR_VARIABLE_3 + YOUR_VARIABLE_4 + YOUR_VARIABLE_5, data=calschool)

regression_final <- lm(acadperf ~ YOUR_VARIABLE_1 + YOUR_VARIABLE_2 + YOUR_VARIABLE_3 + YOUR_VARIABLE_4 + YOUR_VARIABLE_5 + YOUR_VARIABLE_6, data=calschool)

#residual analysis

hist(scale(regression_final$residuals))
qqnorm(scale(regression_final$residuals))
plot(scale(regression_final$fitted), scale(regression_final$residuals))

#standardized residual analysis (how many residuals are more than two deviations away)

regression_final$standardized.residuals <- rstandard(regression_final)

regression_final$large_residual <- regression_final$standardized.residuals >2 | regression_final$standardized.residuals < -2

sum(regression_final$large_residual)
# this value gives us the number of residuals with an absolute value more than 2.

#standardized coefficients
lm(scale(acadperf) ~ scale(YOUR_VARIABLE_1) + scale(YOUR_VARIABLE_2) + scale(YOUR_VARIABLE_3) + scale(YOUR_VARIABLE_4) + scale(YOUR_VARIABLE_5 + scale(YOUR_VARIABLE_6), data=calschool) 

#YOU MAY HAVE MROE VARIABLES THAN THE MODEL ABOVE. THAT IS OK. 
#JUST MAKE SURE ALL YOUR VARIABLES IN YOUR FINAL MODEL ARE IN THE STANDARDIZED COEFFICIENTS MODEL.

#this will print the standardized coefficients in the console.

#multicollinearity test
vif(regression_final)

#durban-watson
dwt(regression_final)

#extra credit

calschool$high_mealcat <- ifelse(calschool$mealcat == 3, 1, 0)
calschool$med_mealcat <- ifelse(calschool$mealcat == 2, 1, 0)
calschool$low_mealcat <- ifelse(calschool$mealcat == 1, 1, 0)

calschool$log_acadperf <- log(calschool$acadperf)
regression_log <- lm(log_acadperf ~ high_mealcat, data=calschool)
summary(regression_log)

#how we get cook's distance

cook_regression_1 <- cooks.distance(regression_1)

plot(cook_regression_1,ylab="Cooks distances")


#how we get cook's distance (regression_final)

cook_final <- cooks.distance(regression_final)

plot(cook_final,ylab="Cooks distances")

# NOTE: IN R, WE SAVE OUR WORK IN A DIFFERENT WAY THAN THE TRADITIONAL METHOD. 
# TO CONTINUE WORKING ON THIS, SAVE EACH LINE THAT YOU ENTER IN A SEPARATE DOCUMENT.
# I HIGHLY RECOMMEND A TEXT EDITOR, SUCH AS NOTEPAD in WINDOWS or TEXT EDITOR IN OS X.
# WORD SOMETIMES DOES NOT LET YOU COPY PASTE IN.
# WE NEVER SAVE ANYTHING IN THE R ENVIRONMENT -- WE JUST COPY PASTE CODE LIKE THIS INTO R.
# I WILL GO OVER THIS ON THURSDAY


# I RECOMMEND LEAVING COMMENTS FOR YOURSELF LIKE THIS THAT WILL TELL YOU WHERE YOU ARE IN YOUR ANALYSIS
# IF YOU HAVE ANY QUESTIONS ABOUT R IN THIS ASSIGNMENT PLEASE EMAIL ANDY







